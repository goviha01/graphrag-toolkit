topic: Amazon Neptune Instance Resource Allocation

  entities:
  
    Amazon Neptune|Service
    Amazon EC2|Service
    Neptune|Service
    DB instances|Product
    DFE query engine|Software
    CloudWatch|Service
    
  proposition: Amazon EC2 instance types are used in Neptune.
    
    entity-entity relationships:
    Amazon EC2|USED_IN|Neptune
    
    entity-attributes:
    
  proposition: Amazon EC2 instance sizes are used in Neptune.
  
    entity-entity relationships:
    Amazon EC2|USED_IN|Neptune
  
    entity-attributes:
    
  proposition: Each Amazon EC2 instance type used in Neptune offers a defined amount of compute (vCPUs).
  
    entity-entity relationships:
    Amazon EC2|USED_IN|Neptune
  
    entity-attributes:
    Amazon EC2|HAS_COMPUTE|vCPUs
    
  proposition: Each Amazon EC2 instance size used in Neptune offers a defined amount of compute (vCPUs).
  
    entity-entity relationships:
    Amazon EC2|USED_IN|Neptune
  
    entity-attributes:
    Amazon EC2|HAS_COMPUTE|vCPUs
    
  proposition: Each Amazon EC2 instance type used in Neptune offers a defined amount of system memory.
  
    entity-entity relationships:
    Amazon EC2|USED_IN|Neptune
  
    entity-attributes:
    Amazon EC2|HAS_MEMORY|system memory
    
  proposition: Each Amazon EC2 instance size used in Neptune offers a defined amount of system memory.
  
    entity-entity relationships:
    Amazon EC2|USED_IN|Neptune
  
    entity-attributes:
    Amazon EC2|HAS_MEMORY|system memory
    
  proposition: The primary storage for Neptune is external to the DB instances in a cluster.
  
    entity-entity relationships:
    Neptune|HAS_STORAGE|primary storage
    DB instances|PART_OF|cluster
  
    entity-attributes:
    Neptune|STORAGE_LOCATION|external
    
  proposition: The external primary storage lets compute and storage capacity scale independently of each other.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Compute resources can be scaled in Neptune.
  
    entity-entity relationships:
    
    entity-attributes:
    Neptune|HAS_CAPABILITY|scalable compute resources
    
  proposition: Instance families have differences between each other.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: In all instance families, vCPU resources are allocated to support two (2) query execution threads per vCPU.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: The support for two query execution threads per vCPU is dictated by the instance size.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: When determining the proper size of a given Neptune DB instance, you need to consider the possible concurrency of your application.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: When determining the proper size of a given Neptune DB instance, you need to consider the average latency of your queries.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: You can estimate the number of vCPUs needed using the formula vCPUs=(latencyxconcurrency)/2.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: In the vCPU estimation formula, latency is measured as the average query latency in seconds.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: In the vCPU estimation formula, concurrency is measured as the target number of queries per second.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: SPARQL queries can use more than one execution thread per query under certain circumstances when using the DFE query engine.
  
    entity-entity relationships:
    
    entity-attributes:
    DFE query engine|SUPPORTS|SPARQL queries
    
  proposition: openCypher queries can use more than one execution thread per query under certain circumstances when using the DFE query engine.
  
    entity-entity relationships:
    
    entity-attributes:
    DFE query engine|SUPPORTS|openCypher queries
    
  proposition: Gremlin read queries can use more than one execution thread per query under certain circumstances when using the DFE query engine.
  
    entity-entity relationships:
    
    entity-attributes:
    DFE query engine|SUPPORTS|Gremlin read queries
    
  proposition: When initially sizing your DB cluster, start with the assumption that each query will consume a single execution thread per execution.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: You should scale up if you observe back pressure into query queue.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Back pressure into query queue can be observed by using the `/gremlin/status` API.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Back pressure into query queue can be observed by using the `/oc/status` API.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Back pressure into query queue can be observed by using the `/sparql/status` API.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Back pressure into query queue can be observed using the `MainRequestsPendingRequestsQueue` CloudWatch metric.
  
    entity-entity relationships:
    
    entity-attributes:
    CloudWatch|HAS_METRIC|MainRequestsPendingRequestsQueue
    
  proposition: System memory on each instance is divided into two primary allocations: buffer pool cache and query execution thread memory.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Approximately two thirds of the available memory in an instance is allocated for buffer-pool cache.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Buffer-pool cache is used to cache the most recently used components of the graph for faster access on queries that repeatedly access those components.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Instances with a larger amount of system memory have larger buffer pool caches.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Larger buffer pool caches can store more of the graph locally.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: A user can tune for the appropriate amount of buffer-pool cache by monitoring the buffer cache hit and miss metrics available in CloudWatch.
  
    entity-entity relationships:
    
    entity-attributes:
    CloudWatch|HAS_METRICS|buffer cache hit and miss metrics
    
  proposition: You may want to increase the size of your instance if the cache hit rate drops below 99.9% for a consistent period of time.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: A cache hit rate dropping below 99.9% for a consistent period suggests that the buffer pool is not big enough.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: When the buffer pool is not big enough, the engine is having to fetch data from the underlying storage volume more often than is efficient.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: The remaining third of system memory is distributed evenly across query execution threads.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Some memory remains for the operating system after distributing memory across query execution threads.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: Some memory remains for a small dynamic pool for threads to use as needed after distributing memory across query execution threads.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: The memory available for each thread increases slightly from one instance size to the next up to an `8xl` instance type.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: At `8xl` instance type size, the memory allocated per thread reaches a maximum.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: The time to add more thread memory is when you encounter an `OutOfMemoryException` (OOM).
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: OOM exceptions occur when one thread needs more than the maximum memory allocated to it.
  
    entity-entity relationships:
    
    entity-attributes:
    
  proposition: An OOM exception is not the same as the entire instance running out of memory.
  
    entity-entity relationships:
    
    entity-attributes: