{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a0c66c",
   "metadata": {},
   "source": [
    "# 1a - Customising Extraction\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Complete <a href=\"../../../../nbclassic/notebooks/graphrag-toolkit/1-Indexing.ipynb\"><b>Exercise 1 - Indexing</b></a> before beginning these additional exercises.\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "You are now going to add some JSON data to your graph using custom prompts and a list of preferred entity classifications.\n",
    "\n",
    "The JSON data to be added to the graph represents the results of calls to the Amazon Neptune `describe-db-instances` and Amazon EC2 `describe-security-groups` management API methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47756039",
   "metadata": {},
   "source": [
    "### üîç 1a.1 Review the JSON data\n",
    "\n",
    "Run the cells below to view the JSON data to be indexed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/neptune/db.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a18dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/neptune/sg.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50462788",
   "metadata": {},
   "source": [
    "### üîç 1a.2 Review the custom prompts\n",
    "\n",
    "You can customize the extraction process using custom prompts and a list of preferred entity classifications.\n",
    "\n",
    "Run the cells below to view the custom prompts for extracting a) propositions, and b) topics, statements and facts from the JSON source documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e02f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat prompts/extract-propositions-json.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat prompts/extract-topics-json.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c29a71",
   "metadata": {},
   "source": [
    "### üéØ 1a.3 Extract and build from JSON documents\n",
    "\n",
    "The following cell combines the Extract and Build stages into a single operation: `extract_and_build()`. \n",
    "\n",
    "The Extract stage uses the custom prompts discussed above. This prompt is further parameterized with a list of preferred entity classifications. These entity classifications help guide the LLM to label entities (e.g. database instances, endpoints and VPCs) in a consistent manner.\n",
    "\n",
    "Run the code below to extract data from the two JSON files and build the graph and vector stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphIndex\n",
    "from graphrag_toolkit.lexical_graph import IndexingConfig, ExtractionConfig, BuildConfig\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.indexing.load import JSONArrayReader\n",
    "from graphrag_toolkit.lexical_graph.indexing.build import Checkpoint\n",
    "from graphrag_toolkit.lexical_graph.utils.io_utils import read_text\n",
    "\n",
    "def get_metadata(data):\n",
    "    metadata = {}\n",
    "    if 'GroupId' in data:\n",
    "        metadata['GroupId'] = f\"GroupId: {data.get('GroupId', '')}\"\n",
    "    if 'DBInstanceIdentifier' in data:\n",
    "        metadata['DBInstanceIdentifier'] = f\"DBInstanceIdentifier: {data.get('DBInstanceIdentifier', '')}\"\n",
    "    return metadata\n",
    "\n",
    "with (\n",
    "    GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE']) as graph_store,\n",
    "    VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'], index_names=['chunk']) as vector_store\n",
    "):\n",
    "\n",
    "    config = IndexingConfig( \n",
    "        chunking=None,\n",
    "        extraction=ExtractionConfig(\n",
    "            extract_propositions_prompt_template=read_text('./prompts/extract-propositions-json.txt'),\n",
    "            extract_topics_prompt_template=read_text('./prompts/extract-topics-json.txt'),\n",
    "            preferred_entity_classifications=[\n",
    "                'DBInstance',\n",
    "                'DBClusterIdentifier',\n",
    "                'DBInstanceClass',\n",
    "                'Endpoint',\n",
    "                'SecurityGroup',\n",
    "                'DBSubnetGroup',\n",
    "                'VPC',\n",
    "                'Subnet',\n",
    "                'SubnetAvailabilityZone',\n",
    "                'IPPermissionsEgress',\n",
    "                'IPPermissions'\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    checkpoint = Checkpoint('1-extract-build')\n",
    "\n",
    "    graph_index = LexicalGraphIndex(\n",
    "        graph_store, \n",
    "        vector_store,\n",
    "        indexing_config=config\n",
    "    )\n",
    "\n",
    "    reader = JSONArrayReader(metadata_fn=get_metadata)\n",
    "    \n",
    "    graph_index.extract_and_build(\n",
    "        nodes=reader.load_data('./source-data/neptune/db.json'), \n",
    "        show_progress=True,\n",
    "        checkpoint=checkpoint\n",
    "    )\n",
    "    \n",
    "    graph_index.extract_and_build(\n",
    "        nodes=reader.load_data('./source-data/neptune/sg.json'), \n",
    "        show_progress=True,\n",
    "        checkpoint=checkpoint\n",
    "    )\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1417d",
   "metadata": {},
   "source": [
    "### üéØ 1a.4 Visualise the extracted data\n",
    "\n",
    "Once again, you can view the extracted data. The code below supplies some filter criteria to the visualisation so that only the newly extracted data is displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73995319",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASSIC = True\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.visualisation import GraphNotebookVisualisation\n",
    "\n",
    "v = GraphNotebookVisualisation(nb_classic=NB_CLASSIC)\n",
    "\n",
    "source_filter = [\n",
    "    {'filename': 'db.json'},\n",
    "    {'filename': 'sg.json'}\n",
    "]\n",
    "\n",
    "v.display_sources(filter=source_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970716b3",
   "metadata": {},
   "source": [
    "You can also view _all_ of the entities that have been extracted so far. Notice how the database and security group entities conform to the list of preferred entity classifications supplied during the extract operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0571b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.display_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec37ef",
   "metadata": {},
   "source": [
    "### üéØ 1a.5 Visualise the inferred schema\n",
    "\n",
    "Besides creating nodes that represent sources, chunks, topics, statememts, facts and entities, the GraphRAG Toolkit also creates schema nodes that represent the inferred domain sematics at the entity-relationship tier (the lowest tier of the hierarchical lexical graph structure). You can view this schema by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.display_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61a393",
   "metadata": {},
   "source": [
    "This ability to create an inferred schema will become important in the third notebook **03 - Agentic Use Cases**, when you create domain-specific tools for use by an AI agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396afde9",
   "metadata": {},
   "source": [
    "### üéØ 1a.6 Query across the data\n",
    "\n",
    "You're now in a position to ask a question of your data. The following cell asks a question that requires joining across the two sources of data (the Neptune clusters described in one of the JSON files, and the instance family descriptions from the Neptune documentation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "\n",
    "with (\n",
    "    GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE']) as graph_store,\n",
    "    VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE']) as vector_store\n",
    "):\n",
    "\n",
    "    query_engine = LexicalGraphQueryEngine.for_traversal_based_search(\n",
    "        graph_store, \n",
    "        vector_store,\n",
    "        streaming=True,\n",
    "        no_cache=True\n",
    "    )\n",
    "\n",
    "    response = query_engine.query(\"Can gr-1756394635-cluster currently use the lookup cache?\")\n",
    "    \n",
    "response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
