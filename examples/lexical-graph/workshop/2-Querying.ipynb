{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91483ed5",
   "metadata": {},
   "source": [
    "# 2 - Querying (20 mins)\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "In this exercise you will learn how to query data. The exercise uses a different dataset from the first exercise.\n",
    "\n",
    "In the course of this exercise you will:\n",
    "  \n",
    "  - Inspect the press releases and pre-extracted chunks that will be used to build the new dataset\n",
    "  - Build the new dataset\n",
    "  - Learn about the GraphRAG Toolkit's multi-tenancy feature\n",
    "  - Query the data using traditional vector similarity search\n",
    "  - Query the data using the GraphRAG Toolkit\n",
    "  - Visualise the results\n",
    "  - Inspect the underlying results generated by the GraphRAG Toolkit\n",
    "  - Learn about the role of entity network contexts in querying the data\n",
    "  - Visualise the entity networks used when querying the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39412c5a",
   "metadata": {},
   "source": [
    "## Query Process\n",
    "\n",
    "There are two parts to querying: _retrieve_ and _generate_:\n",
    "\n",
    "#### Retrieve\n",
    "\n",
    "  1. Create an embedding for the user question\n",
    "  2. This embedding is used to conduct a _top k similarity search_ for chunk ids\n",
    "  3. The chunk ids form the _entry points_ into the graph for a set of graph traversals\n",
    "  \n",
    "#### Generate\n",
    "\n",
    "  4. The graph traversal results are submitted together with the user question to an LLM, which generates a response\n",
    "  \n",
    "Some workloads will only want the structured results of the Retrieve operation (steps 1-3), while others will want the natural language response returned by the Generate operation (steps 1-3 plus step 4). The GraphRAG Toolkit supports both options.   \n",
    "\n",
    "\n",
    "![Querying](./images/query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e026ca",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Build a New Dataset\n",
    "\n",
    "First, you're going to load another dataset. This dataset has already been pre-extracted from a set of press releases ‚Äì¬†all you need do is build the graph and vector stores from the pre-extracted chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e01ce",
   "metadata": {},
   "source": [
    "### üîç 2.1 Inspect the press releases\n",
    "  \n",
    "Take a moment to inspect one of the press releases. Pick one from the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba1d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/ecorp-md/Revolutionizing Personal Computing.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75eb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/ecorp-md/Countdown to Christmas.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/ecorp-md/AnyCompany Logistics Slashes Shipping Times to UK with Turquoise Canal Shortcut.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/ecorp-md/Turquoise Canal Blocked by Landslides.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3d1a3",
   "metadata": {},
   "source": [
    "The press releases tell a story. In summary:\n",
    "\n",
    "  - Example Corp sells Widgets\n",
    "  - There is a huge Christmas demand for Widgets in the UK\n",
    "  - Example Corp has partnered with AnyCompany Logistics\n",
    "  - AnyCompany Logistics is cutting shipping times by using the Turquoise Canal\n",
    "  - The Turquoise Canal is blocked, causing delays\n",
    "  \n",
    "![Corpus](./images/corpus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd3172",
   "metadata": {},
   "source": [
    "### üîç 2.2 Inspect the pre-extracted chunks\n",
    "  \n",
    "Also take a look at one of the pre-extracted chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d450083",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat source-data/ecorp/aws::69d4badc:968c/aws::69d4badc:968c:7281c2ee.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9cdc4c",
   "metadata": {},
   "source": [
    "This pre-extracted chunk includes a vector embedding. Normally, embeddings would be calculated _during_ the Build stage, but for the purposes of this workshop, to avoid frequent calls to Bedrock, we've precalculated the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7394b68",
   "metadata": {},
   "source": [
    "### üéØ 2.3 Build the press release lexical graph\n",
    "\n",
    "Build the dataset using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphIndex\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.indexing.load import FileBasedDocs\n",
    "\n",
    "docs = FileBasedDocs(\n",
    "    docs_directory='source-data',\n",
    "    collection_id='ecorp'\n",
    ")\n",
    "\n",
    "with (\n",
    "    GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE']) as graph_store,\n",
    "    VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'], index_names=['chunk']) as vector_store\n",
    "):\n",
    "    graph_index = LexicalGraphIndex(\n",
    "        graph_store, \n",
    "        vector_store,\n",
    "        tenant_id='ecorp' # tenant id - loads the data into a tenant-specific lexical graph\n",
    "    )\n",
    "\n",
    "    graph_index.build(\n",
    "        docs, \n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "print('Build complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae5af7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Multi-Tenancy\n",
    "\n",
    "Notice that in the code above, the `LexicalGraphIndex` was initialised with `tenant_id='ecorp'`. This loads the press release data into a _separate_ lexical graph (named `ecorp`).\n",
    "\n",
    "Multi-tenancy is a feature in the GraphRAG Toolkit that allows hosting multiple separate lexical graphs within the same underlying graph and vector stores. This capability allows you to manage and query different sets of data within a shared infrastructure.\n",
    "\n",
    "Multi-tenancy can be particularly useful in the following scenarios:\n",
    "\n",
    "  - Creating separate lexical graphs for different collections of documents\n",
    "  - Managing individual user data\n",
    "  - Handling different domains within the same infrastructure\n",
    "  - Running multiple dev and test workloads\n",
    "\n",
    "If you later run the optional notebook, **03 - Agentic Use Cases**, you will see how this ability to host multiple graphs in the same database is used to create different domain-specific tools for use by an AI agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148413d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Query the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd502df",
   "metadata": {},
   "source": [
    "\n",
    "### üéØ 2.4 Query the data using vector RAG\n",
    "\n",
    "Before you explore the graph-enabled search capabilties of the GraphRAG Toolkit, you'll query the press release data using pure vector search alone.\n",
    "\n",
    "Imagine you are an analyst tasked with predicting the fortunes of Example Corp. What kinds of questions might you ask? How about: \n",
    "\n",
    "  - ***What are the sales prospects for Example Corp in the UK?***\n",
    "  \n",
    "The pure vector-based approach in the cell below uses similarity search to find relevant chunks that can help answer the question. Given your reading of the press releases (or the summaries above), what kind of answer might you expect vector search to produce? Run the cell below to find out.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "This is not a full-blown vector RAG solution. Production RAG solutions typically incorporate multiple techniques, including vector search, semantic search, and reranking. The goal here is simply to show what vector search alone can achieve, and then, later, what we can add using the graph. As you'll see, vector search remains a powerful and important tool for building RAG solutions.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "‚è≥ <b style=\"color:black;\">Wait</b>\n",
    "    \n",
    "The refresh interval for indexes in OpenSearch Serverless vector search collections is approximately <a href=\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-overview.html#serverless-limitations\" target=\"_blank\">60 seconds</a>. This means that newly inserted vectors won't be visible for up to a minute, which can negatively impact search results.\n",
    "\n",
    "If you run a query below and get a response that indicates that the search results are empty, wait a few seconds and then re-run the query.\n",
    "\n",
    "This is not a limitation of the GraphRAG Toolkit; rather, it is a feature of the OpenSearch Serverless vector store. Other vector stores (e.g. Amazon Aurora Postgres, Amazon Neptune Analytics) have different characteristics.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "%run './misc/vector_query.py'\n",
    "\n",
    "vector_response = vector_query(\n",
    "    \"What are the sales prospects for Example Corp in the UK?\", \n",
    "    tenant_id='ecorp', # we need to query the 'ecorp' tenant index\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "vector_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572ca41",
   "metadata": {},
   "source": [
    "### Commentary\n",
    "\n",
    "The response is detailed, but it is not complete. It is overly _optimistic_.\n",
    "\n",
    "![Vector Search](./images/vector-search.png)\n",
    "\n",
    "To answer your analyst question fully and effectively, the system must retrieve not only information that is semantically similar to the company and location named in the question (Example Corp, and the UK), but also structurally relevant, potentially _semantically dissimilar_ information regarding Example Corp's supply chain dependencies and any recent events impacting this supply chain. \n",
    "\n",
    "Some of this additional relevant information is missing ‚Äì¬†information about the blockage in the Turquoise Canal ‚Äì¬†and as a result, the response lacks the nuance we need to make an informed decision about Example Corp's fortunes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0adb92d",
   "metadata": {},
   "source": [
    "### üéØ 2.5 Inspect the chunks returned by vector search\n",
    "\n",
    "To see the content that was used to generate the response, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(vector_response.source_nodes):\n",
    "    print(f'Chunk {i+1}:\\n\\n{n.text}\\n\\n------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1802454",
   "metadata": {},
   "source": [
    "### üéØ 2.6 Query the data using graph-enhanced search\n",
    "\n",
    "Run the cell below to use the GraphRAG Toolkit's graph-enhanced search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0391c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphQueryEngine\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "\n",
    "with (\n",
    "    GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE']) as graph_store,\n",
    "    VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE']) as vector_store\n",
    "):\n",
    "\n",
    "    query_engine = LexicalGraphQueryEngine.for_traversal_based_search(\n",
    "        graph_store, \n",
    "        vector_store,\n",
    "        streaming=True,\n",
    "        tenant_id='ecorp', # we need to query the 'ecorp' tenant index\n",
    "        no_cache=True\n",
    "    )\n",
    "\n",
    "    response = query_engine.query(\"What are the sales prospects for Example Corp in the UK?\")\n",
    "\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb3b2f",
   "metadata": {},
   "source": [
    "### Commentary\n",
    "\n",
    "The answer here is more nuanced. Importantly, it identifies that the blockage in the Turquoise Canal poses a potential problem.\n",
    "\n",
    "![Graph Search](./images/graph-search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04e0f4",
   "metadata": {},
   "source": [
    "### üéØ 2.7 Visualize the results\n",
    "\n",
    "You can view the results by the running the visualisation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASSIC = True\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.visualisation import GraphNotebookVisualisation\n",
    "\n",
    "v = GraphNotebookVisualisation(nb_classic=NB_CLASSIC)\n",
    "v.display_results(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742892ed",
   "metadata": {},
   "source": [
    "### üéØ 2.8 Inspect the search results\n",
    "\n",
    "Besides visualising the results, you can also programatically access the structured results generated by the query engine.\n",
    "\n",
    "When you call the `query()` method, the engine retrieves a set of search results from the graph and vector stores, and then passes these search results to an LLM together with a prompt to generate a natural language response to your question.\n",
    "\n",
    "#### Show the context passed to the LLM\n",
    "\n",
    "To see the results passed in the context window to the LLM, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b77842",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23f24a",
   "metadata": {},
   "source": [
    "Notice how these results are structured: sets of statements, grouped by topic and source.\n",
    "\n",
    "#### Show the underlying results:\n",
    "\n",
    "The results passed to the LLM contain only the information necessary to generate a natural language response. However, during the retrieval process, the GraphRAG Toolkit creates a far more detailed set of search results, with individually scored statements annotated with the names of the retriever strategies that found them.\n",
    "\n",
    "To see this more detailed breakdown of the results, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e812205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for n in response.source_nodes:\n",
    "    print(json.dumps(n.metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316da1a8",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Entity Network Contexts\n",
    "\n",
    "Why is the graph-enhanced search more effective at answering our question? As mentioned above, to answer the question effectively, the system must retrieve two types of content:\n",
    "\n",
    "  - Content that is semantically similar to the company and location named in the question (Example Corp, and the UK)\n",
    "  - Structurally relevant, potentially _dissimilar_ content (regarding, for example, Example Corp's supply chain dependencies and any recent events impacting this supply chain)\n",
    "  \n",
    "To access this additional, structurally relevant information, the GraphRAG Tookit uses _entity networks_. Entity networks are one- or two-hop networks that surround important entities and keywords extracted from the question. These entity networks act as 'fingerprints' for content that is structurally relevant, but potentially _dissimilar_ to the question:\n",
    "\n",
    "![Entity Network](./images/entity-network.png)\n",
    "\n",
    "### How entity networks are used in querying\n",
    "\n",
    "Entity network contexts are used in several places in the querying process:\n",
    "\n",
    "#### Dissimilarity searches\n",
    "\n",
    "Entity networks are used to seed similarity searches for potentially relevant content that is _semantically dissimilar_ to the question. The results of these (dis)similarity searches then form the starting points for graph traversals.\n",
    "\n",
    "![Dissimilarity Search](./images/dissimilarity-search.png)\n",
    "\n",
    "#### Enrich the prompt with additional context\n",
    "\n",
    "Entity networks are also used to guide the LLM to focus on relevant search results. The textual representations of the entity networks are added as additional context to the prompt used to generate a response. \n",
    "\n",
    "![Guide LLM](./images/guide-llm.png)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b13db",
   "metadata": {},
   "source": [
    "### üéØ 2.9 Visualise the entity networks used in the query\n",
    "\n",
    "You can view the entity networks used in the query above by the running the visualisation from the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a21482",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.display_entity_contexts(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3582c05",
   "metadata": {},
   "source": [
    "## Next Exercise (Optional)\n",
    "\n",
    "If you have time, go to <a href=\"../../../nbclassic/notebooks/graphrag-toolkit/3-Agentic-Use-Cases.ipynb\"><b>Exercise 3 - Agentic Use Cases</b></a> to continue the workshop exercises."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
